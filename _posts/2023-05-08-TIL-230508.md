### Today I Learned 2023-05-08
---

```
- 목차 -
오늘 공부한 것은 다음과 같습니다. 
1. 네이버 뉴스크롤러 이용 데이터 생성 (파이썬, 예술&인공지능, 현대자동차)
2. 형태소 분석 개념, 분석기(라이브러리) 알아보기
3. 형태소 분석기 PeCab, matplotlib, Wordcloud 이용하여 크롤링한 뉴스데이터 분석하기.
4. 텍스트 마이닝 개념 이해하기. 빈도 분석, TF-IDF 분석하기 
5. 판다스 복습 (10 minute to pandas 타이핑)
6. EDA 복습 (keggle 과제 타이핑)
```
---

- [오늘의 노트](https://www.notion.so/day03-8ad81217d579467aadff51afdf2be87c?pvs=4)
---

### 1. 네이버 뉴스크롤러 이용 데이터 생성
- 선생님이 주신 코드 활용 네이버 뉴스를 크롤링하고 엑셀 파일로 데이터 생성해보았습니다. 
- 눈으로 대략적인 코드 (함수의 구성)을 이해할 수 있었습니다. 그러나 코드를 다시 짜보라고 하면 불가능할 것 같습니다. 아주 오랜 시간이 걸릴 것으로 보입니다. (김인섭 강사님 수업때 만들었던 크롤링 코드와 함께 복습하고 싶습니다.)
- 수업시간에는 네이버 검색 제한으로 데이터 생성이 불가능 했는데, 쉬는시간에 시도했을때 다행히 작동해서, 여러 데이터를 수집해볼 수 있었습니다. 
- 개인적으로 '예술&인공지능' 키워드를 이용해서 관심있는 뉴스를 크롤링하는 것이 흥미롭게 느껴졌습니다. 

### 2. 형태소 분석 개념, 분석기(라이브러리) 알아보기
- 처음에는 형태소 분석기로 konlpy 사용을 시도했는데, JDK 이슈로 실제로 구동은 실패했습니다.
- 선생님이 만든 코드를 PeCab 으로 고쳐 돌려볼 수 있었습니다. 
- PeCab이 긴 텍스트를 나누는데 너무 오랜시간이 걸리는 이슈로 인해서, 기사 내용은 분석하지 못하고 기사 제목만으로 분석 진행했습니다. 
- JDK 설치 및 Mecab활용하여 내용 분석한다면 실제 개인적인 논문 주제를 위한 텍스트 마이닝에도 유의미하게 쓰일 것으로 기대됩니다. 


### 3. 형태소 분석기 PeCab, matplotlib, Wordcloud 이용 뉴스데이터 분석
- 텍스트 마이닝(Corpus 전처리) 단계
	* 텍스트 입력(Input Text, Corpus) : 말뭉치(Corpus)는 언어 연구를 위해 텍스트를 컴퓨터가 읽을 수 있는 형태로 모아 놓은 언어 자료이다. 매체, 시간, 공간, 주석 단계 등의 기준에 따라 다양한 종류가 있다. 말뭉치(Corpus) 입력을 통해 텍스트 분석이 시작된다. 
	* Cleaning : 필요없는 텍스트를 모두 제거한다.
	* Make Canonical Form : 의미가 같은 서로 다른 단어를 하나의 표현으로 통일한다. 실제로는 이 과정에서 수만가지 케이스가 발생할 수 있기에 이를 진행하면 텍스트 마이닝의 정확도나 신뢰도는 상승할 수 있지만, 안하고 진행할 수도 있다. 딥러닝에서는 이 과정을 생략해도 괜찮은 결과를 출력하는 방법론이 있다. 
		* canonical form : 원형, 복잡하고 다양한 모습으로 바뀌기 이전의 단순한 모습.
	* Tokenized Corpus : Cleaning한 Corpus(Cleand Corpus)를 특정 단위 (token)로 분할한 말뭉치(Corpus). 언어에 따라 다르다. 
		* Token : 자소, 글자, 형태소, 단어, 문장 등
		* 딥러닝에서는 학습 편의를 위해 새로운 토큰을 정의하기도 한다.
		* 품사 단위로 토크나이징 하는 경우도 많다.
	* [Vector(Document-Term Matrix)](https://wikidocs.net/24559) : 말뭉치의 embedding 작업을 통해서 분절된 단어로 구성된 행렬표가 만들어진다. 머신러닝에서 보통 사용한다. 
	* Lookup Table : 분절된 단어를 Matrix 구성하지만, Row 하나하나가 특정 토큰이며, Column 하나가 특별한 의미 없는  숫자들로 구성된 테이블. 보통 딥러닝에 사용한다. 
	* Modeling(NLU:Natural Language Understanding) : 모델을 통해 의미를 찾기 위해 진행하는 프로세스. 토픽 모델링만으로도 연구 성과로 인정받으며, KCI에도 토픽 모델링에 대한 논문이 많다. Keyword Extraction, Topic Modeling, Sentiment Analysis, Text Summarization, Semantic Network Analysis(의미 연결망 분석) 등등...
	* Numbers : 분석 결과가 수치값으로 나온다. 이를 해석하는 방법? : 인덱스가 나오는 경우, 수치값 자체가 의미를 갖는 경우, 확률 값으로 나오는 경우가 있다. 
	* Plot : 시각화(Visualization)과정. 우리는 모두 텍스트 전문가가 아니다. 시각화를 하면 다양한 인사이트를 도출할 수 있다. 많이 하는 건 Wordcloud, pyLDAvis 등. 

### 4. 빈도분석, TF-IDF 분석 개념정리 및 실습.
- 오늘 빈도분석과 텍스트 마이닝은 선생님이 짜온 코드를 돌려보는 수준에서 진행했습니다. 따라가는데 큰 무리는 없었습니다. 다만 빈도분석, Text Mining 모두 처음 접하는 개념인 만큼 레퍼런스 통해서 보충할 필요가 있음을 느꼈습니다.
- 특히, Mecab으로 content 분석은 이번주 내에 꼭 진행해보고 싶습니다. 오늘은 기본 개념 이해에 중점을.
* TF-IDF (Term-Frequency - Inverse Document Frequency) : 정보 검색, 텍스트 마이닝에 사용하는 '가중치'. 여러 문서로 이루어진 문서군 내에서 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지 나타내는 통계적 수치. 문서의 핵심어 추출하거나, 검색엔진에서 검색 결과의 순위 결정, 문서 사이 비슷한 정도를 구하는 등의 용도로 사용. 
	* TF : 특정한 단어가 특정한 문서에서 얼마나 자주 사용되는지 나타내는 수. 클 수록 자주 사용된다고 볼 수 있다. 
	* IDF : 단어가 문서군 전체에서 자주 등장하는 빈도를 DF(Document Frequency)라고 하며, 문서군 전체에서 단어가 자주 등장하면 그만큼 중요도가 떨어진다고 판정하고, DF의 역수를 빈도 계산에 사용한다. 이를 IDF(Inverse Document Frequency)라고 한다. 
	* 따라서, TF-IDF는 TF와 IDF를 곱한 값으로 나타내며, 이 값이 클 수록 문서군 내에서 중요한 키워드라고 판정한다. 

### 5-6. 판다스, EDA 복습
- 수업 들을땐 이해했다고 생각했던 판다스, 넘파이, 그리고 EDA. 과제를 제대로 안따라 했더니 다 까먹었습니다.
- 앞으로 진행한 팀플에서 방해가 되면 안되겠기에, 너무 생각 많이 하지 말고 머리에 때려박을 방법을 고민했습니다.
- 그래서 결론은 따라쓰기입니다. 
- 매일매일 판다스, EDA 과제를 따라씁니다. 
- 통계학 개론, 머신러닝, 딥러닝 알고리즘은 우선 뒤로 하고, EDA를 더욱 능숙하게 수행할 수 있도록 트레이닝 합니다. 
- 한 번 따라 쓰는데 꽤 시간이 걸리는 관계로, 하루 1 - 2시간씩 꾸준히 진행합니다. 과연? 판다스가 익숙해질 수 있을까요? 

---

### 앞으로 과제 
- 수업때 제시된 EDA 과제 전부 복습하기. 가능하면 하나의 주피터 노트북 파일에 EDA 과제를 정리하고, 이게 완료되면 블로깅하고 싶습니다. (결과가 괜찮으면 이어드림 슬랙에도 공유할 수 있으면 좋겠습니다.)
- 기타 수업에서 진행했던 파이썬, SQL, 이산수학 과제를 다시 한 번 복습합니다. (기한 : 5월 내)
	* 우선은 여러 갈래로 지식을 확장하는 것보다는 한 가지를 잘 숙달하는 것에 목표를 두고자 합니다.
	* 하나가 잘 되면 나머지는 따라온다는 생각을 믿고.

---

### 기타
- '만들다' 스터디 첫 모임이 있었습니다. OT로 진행했으며 구성원의 얼굴과 이름, 그리고 과정을 통해 하고 싶은 것을 간단히 공유하면서 앞으로 스터디가 어떤 방향으로 진행되었으면 좋겠는지 나누었습니다. 다양한 분야와 경험을 가진 분들을 만나게 되어 매우 기뻤고 설렜습니다. 빠르게 성장하여 무엇이든 '만들다' 프로젝트에 도움이 될 수 있도록!
- 'PLAY HOME, SWEET HOME' 프로젝트의 런칭이 한 달 앞으로 다가왔습니다. 프로듀서로 해야 할 일이 많은데, 지난 연휴에 수행을 많이 못해서, 이번 주에는 공부 시간이 끝나고서는 프로듀서 업무에 시간을 많이 할애해서 차질 없이 진행할 수 있도록 하겠습니다.
